\documentclass{article}
\usepackage{fullpage}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{graphicx}


\title{STstuff package vignette}
\author{David Venet}
\date{\today}
\begin{document}
\maketitle
   
   
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This vignette quickly presents the features of the STstuff pakckage:

\begin{enumerate}
\item Estimation of the proportion of each annotation is each spot
\item Determination of expression in annotations
\item Deconvolution of megaclusters
\item Ecotypes
\item Deconvolution of k-means prototypes
\end{enumerate}

\section{Estimation of the proportion of each annotation is each spot}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Detailed morphological annotations were done on 94 triple negative breast cancer. Using those, the fraction of each annotation in each spot (e.g. the percentage of the spot annotated as tumor) was determined.
Regressors were designed to estimate those fractions from the gene expression data of each spot. Those regressors are available via the command \verb!classifySpots!.

For instance, [ download data and so on ].

Of course, those regressors were made on TNBC on a specific platform and there is no guarantee whatsoever of their usefulness on another dataset.

\section{Determination of expression in annotations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We assume the for each spot of an ST experiment there is an estimate of the presence of a some annotations. A possibility is that a pathologist would have annotated the slide so that it is possible to estimate the fraction of tumor, stroma, lymphocytes and so on in each spot. Another possibility is to use the estimates obtained with \verb!classifySpots!.  Using those, by deconvolution it is possible to estimate the expression related to each annotation, i.e. the gene expressions that would be obtained if only the cells in those annotations were sequenced. In our experience, using the estimates obtained by regression leads to much better results than using the original annotation counts.


\section{Recovery of megaclusters from another dataset}
%%%%%%%%%%%%%%%%%%%%%%
Megaclusters (MC) are inter-patients clusters of intra-patient clusters.
In the TNBC dataset, we determined that there were 14 MC.
The idea is here is to recover from sequencing on the bulk the level of presence of those MC.
The package proposes two functions to do this: a general function (\verb!clustersInOtherDS!) that could be used for any MCs, and the \verb!computeMC! function that uses the MCs that were found in TNBCs.

\section{Determination of ecotypes in another dataset}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
Ecotypes (ET) are groups of tumors that were found by clustering the MC estimates.
It is possible to recover them in other datasets. The packages proposes the function \vers!computeET! to recover them, starting from the MC estimates obtained by \verb!computeMC!.

\section{Deconvolution of k-means prototypes}
%%%%%%%%%%%%%%%%%%%%%%%%
We simulate data, where each spot is a mixture of 3 basic vectors.
Those vectors are chosen to be correlated, as gene expression is.
The parameters of the mixture are taken from a Dirichlet distribution, so that they are often close to 1 but not always.
Then we take the mixture from each spot as the mean of a negative binomial and draw random values from there.
  
<<>>=
library(STstuff);

library(dirmult); # for the Dirichlet (in the simulation)

Nprot = 3; Nspot = 100*Nprot;
Ngene = 500;
gb = rexp(Ngene)^2+1; # Gene specific values
prot = matrix(rexp(Ngene*Nprot), ncol=Nprot) * gb; # prototypes
protl = log(1+1e4*t(prot)/colSums(prot))
mix = rdirichlet(Nspot, alpha=c(1,1,1)*.1) # Mixture from all 3 classes for each spot
base = mix %*% t(prot)
X = matrix(rnbinom(base, mu=base, size=1), ncol=ncol(base));
@

The distribution of the mix is often close to 0 or 1, as wanted.
<<plotHistMix, fig.height=3>>=
hist(mix[,1], breaks=30)
@

From here, we first do a kmeans to get the clusters.
We start from the real prototype to ensure that we get the right ordering.

<<>>=
y = log(1+1e4*X/rowSums(X))
km = kmeans(y, protl);
@

We can see that the cluster centers, although correlated to the correct prototypes, are also correlated to each other.

<<plotCorKM, fig.height=6>>=
pr = t(km$centers)
prO = (exp(pr)-1)*colSums(prot)/1e4;

par(mfrow=c(3,3), mar=c(3,3,.5,.5), mgp=c(1.5,.5,0))
for (i in 1:3)
{ for (j in 1:3)
  { plot(prot[,i], prO[,j], log='xy', xlab=paste("Recovered proto", i),
      ylab=paste("Real proto", j)); #abline(0,1)
    mtext(paste0("Cor:", round(cor(prot[,i], pr[,j], method='s')*100), "%"), side=3, line=-2)
  }
}
@

We can deconvolute the cluster.

<<>>=
deconv = deconvoluteClusters(X, km$cluster, Niter=10)
pr2 = deconv$proto; # pr2 are the new prototypes
@

The new prototypes are still well correlated with the real prototypes, but they are also less correlated to each other.
Note that some correlation is still expected because the original prototypes are also correlated.

<<plotCorDeconv, fig.height=6>>=
par(mfrow=c(3,3), mar=c(3,3,.5,.5), mgp=c(1.5,.5,0))
for (i in 1:3)
{ for (j in 1:3)
  { plot(prot[,i], pr2[,j], xlab=paste("Recovered proto", i),
      ylab=paste("Real proto", j)); abline(0,1)
    mtext(paste0("Cor:", round(cor(prot[,i], pr2[,j], method='s')*100), "%"), side=3, line=-2)
  }
}
@

We do not typically know the number of factors in the mixture. The number of clusters will typically be larger than this. To simulate this, we use a kmeans with 4 groups.

<<>>=
km = kmeans(y, 4, nstart=100);
@

From this, we can use \verb!deconvoluteClusters! function to get the best mixture.
In this case the \verb!rmCutOff! parameter was increased to ensure that the bad cluster is removed, but that's not recommended in practice.
<<echo=TRUE>>=
dec2 = deconvoluteClusters(X, km$cluster, rmCutOff=.6, clean=FALSE)
@

The \verb!Kill! shown is list of cluters that are removed.
Note the calculation is done on a subset of 500 genes that fit the clustering well, then the prototypes  are calculated using \verb!NNMFproto! on all genes.

The clusters recovered can be extracted, their name corresponding to the indices of the original kmeans. The prototypes are a list with two items, \verb!proto! indicating the protoype values and \verb!sigma! giving the extra variance from the negative binomial.

<<>>=
pr3 = dec2$proto$proto
show(colnames(pr3))
show(dim(pr3))
@

We can check that the prototypes still fit well. Of course the ordering is random.

<<plotCorDeconv2, fig.height=6>>=
par(mfrow=c(3,3), mar=c(3,3,.5,.5), mgp=c(1.5,.5,0))
for (i in 1:3)
{ for (j in 1:3)
  { plot(prot[,i], pr3[,j], xlab=paste("Recovered proto", i),
      ylab=paste("Real proto", j)); abline(0,1)
    mtext(paste0("Cor:", round(cor(prot[,i], pr3[,j], method='s')*100), "%"), side=3, line=-2)
  }
}
@


\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%


\end{document}
